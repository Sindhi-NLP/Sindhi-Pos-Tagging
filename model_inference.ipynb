{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e67392-3b23-4ca6-9324-ae7cca2691c2",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This code snippet sets up the environment for performing inference using a pre-trained Conditional Random Field (CRF) model. It includes essential functions for data preparation and model loading.\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "* **Import:** Imports the necessary `pycrfsuite` library for CRF operations.\n",
    "* **Feature Conversion:** Defines a `convert_features` function to transform feature data into a format compatible with PyCRFSuite.\n",
    "* **Model Loading:** Creates a `pycrfsuite.Tagger` instance and loads a pre-trained CRF model from a file.\n",
    "* **Sentence Preprocessing:** Defines a `prepare_sentence_for_tagging` function to process sentences into a format suitable for the CRF model, including feature extraction and handling sentence boundaries.\n",
    "\n",
    "This code provides a foundation for subsequent steps, such as making predictions using the loaded model and evaluating its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3d416-ba9e-4d7a-a8c6-e7ad555f7bf2",
   "metadata": {},
   "source": [
    "**Importing Library and Loading Model (Markdown Format)**\n",
    "\n",
    "This code snippet in your Jupyter Notebook performs two key actions:\n",
    "\n",
    "1. **Importing Library:**\n",
    "   - `import pycrfsuite` imports the necessary `pycrfsuite` library, which provides functionalities for working with Conditional Random Field (CRF) models in Python.\n",
    "\n",
    "2. **Loading Pre-trained Model:**\n",
    "   - `tagger = pycrfsuite.Tagger()` creates a `Tagger` object from the `pycrfsuite` library. This object will be used for making predictions with the trained CRF model.\n",
    "   - `tagger.open('model.crfsuite')` opens a pre-trained CRF model from the file named 'model.crfsuite' and loads it into the `tagger` object. Now, the model is ready to be used for tasks like sequence labeling.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "In the following cells of your notebook, you can leverage this loaded model for various purposes. Here are some potential continuations:\n",
    "\n",
    "* Define functions to preprocess your data and convert it into a format suitable for the model.\n",
    "* Use the `tagger.tag(features)` method to make predictions on new data (features) and obtain the corresponding labels.\n",
    "* Evaluate the model's performance on a held-out test dataset.\n",
    "\n",
    "By understanding this code, you can effectively utilize a pre-trained CRF model for sequence labeling tasks in your natural language processing projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc68041f-a15a-4c1c-88c4-cce59a3a738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.closing at 0x1bc4b88e570>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycrfsuite\n",
    "# Convert features to the format required by pycrfsuite\n",
    "def convert_features(X):\n",
    "    return [{k: str(v) for k, v in x.items()} for x in X]\n",
    "\n",
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open('sindhiposmodel.crfsuite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7953bc4-3884-40cf-a2d5-7af9c6820c75",
   "metadata": {},
   "source": [
    "**Code Explanation:**\n",
    "\n",
    "This code defines a function `prepare_sentence_for_tagging` that preprocesses a sentence into a format suitable for a CRF tagger.\n",
    "\n",
    "**Breakdown:**\n",
    "\n",
    "1. **Function Definition:**\n",
    "   * `def prepare_sentence_for_tagging(sentence):` defines a function that takes a sentence as input.\n",
    "\n",
    "2. **Tokenization:**\n",
    "   * `tokens = sentence.split()` splits the sentence into a list of tokens based on whitespace.\n",
    "\n",
    "3. **Feature Extraction:**\n",
    "   * `prepared_sentence = []` initializes an empty list to store processed tokens.\n",
    "   * The `for` loop iterates over each token in the tokenized sentence:\n",
    "     * A dictionary `token_dict` is created to store features for the current token.\n",
    "     * The word itself is added as the 'word' feature.\n",
    "     * For the first token, a 'BOS' (Beginning-of-Sentence) feature is added.\n",
    "     * For tokens other than the first, the previous token is added as the '-1:word' feature.\n",
    "     * For the last token, an 'EOS' (End-of-Sentence) feature is added.\n",
    "     * For tokens other than the last, the next token is added as the '+1:word' feature.\n",
    "     * The processed token dictionary is appended to the `prepared_sentence` list.\n",
    "\n",
    "4. **Return Prepared Sentence:**\n",
    "   * The function returns the `prepared_sentence` list, which contains dictionaries representing each token with its corresponding features.\n",
    "\n",
    "**Example Usage:**\n",
    "\n",
    "* An example sentence in Urdu is provided.\n",
    "* The `prepare_sentence_for_tagging` function is called to preprocess the sentence.\n",
    "* The processed sentence is passed to the `tagger.tag` function (assuming `tagger` and `convert_features` are defined elsewhere) to obtain predicted labels.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* This function prepares the sentence for CRF tagging by extracting relevant features.\n",
    "* The features include the word itself, previous and next words (contextual information), and sentence boundaries (BOS and EOS).\n",
    "* The output format is a list of dictionaries, compatible with the expected input format for CRF models.\n",
    "\n",
    "This code provides a foundation for preprocessing text data for CRF-based sequence labeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "864d08a6-1b63-451d-b6c7-dada45945d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOUN', 'VERB', 'ADP', 'ADV', 'NOUN', 'ADV', 'VERB', 'VERB', 'PERIOD']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def prepare_sentence_for_tagging(sentence):\n",
    "    # Tokenize the sentence (simple split on whitespace)\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Prepare the list of dictionaries\n",
    "    prepared_sentence = []\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        token_dict = {'word': token}\n",
    "        \n",
    "        if i == 0:\n",
    "            token_dict['BOS'] = 'True'\n",
    "        else:\n",
    "            token_dict['-1:word'] = tokens[i-1]\n",
    "        \n",
    "        if i == len(tokens) - 1:\n",
    "            token_dict['EOS'] = 'True'\n",
    "        else:\n",
    "            token_dict['+1:word'] = tokens[i+1]\n",
    "        \n",
    "        prepared_sentence.append(token_dict)\n",
    "    \n",
    "    return prepared_sentence\n",
    "\n",
    "# Example usage\n",
    "sentence = \"يقين ڪرڻ سان اڪثر ڌوڪو ئي ملي ٿو .\"\n",
    "prepared = prepare_sentence_for_tagging(sentence)\n",
    "tagger.tag(convert_features(prepared))\n",
    "[(tag,word) for tag,word in zip(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7d562e-0917-451c-87c7-4f80c6d3dfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
